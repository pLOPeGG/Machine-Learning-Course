{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12, 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan de Classification\n",
    "[x] Intro Classification\n",
    "\n",
    "[x] Perceptron\n",
    "\n",
    "[x] Multilayer\n",
    "\n",
    "[x] Other models (SVM, Bayesian...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some toy data\n",
    "\n",
    "centroids = np.array([[-2, -2], [2, 2]])\n",
    "labels = np.array([0, 1])\n",
    "\n",
    "x = []  # Features\n",
    "y = []  # Labels\n",
    "\n",
    "n = 500\n",
    "\n",
    "for p, l in zip(centroids, labels):\n",
    "    x.extend( np.concatenate((np.random.normal(p[0], 1, n//2), \n",
    "                              np.random.normal(p[1], 1, n//2))).reshape(2, n//2).T)\n",
    "    y.extend([l] * (n//2))\n",
    "    \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "colours = ['b' if l==0 else 'r' for l in y]\n",
    "plt.scatter(x[..., 0], x[..., 1], c=colours)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "Modèle très simple en 2 dimensions :\n",
    "![Perceptron](img/perceptron.png)\n",
    "\n",
    "* $x_1$ et $x_2$ les coordonnées d'un point\n",
    "* $w_1$, $w_2$ et $b$ les paramètres du modèle\n",
    "* $f$ est la fonction heaviside ($0$ si $x < 0$, $1$ sinon)\n",
    "* $y$ est la sortie du modèle pour l'entrée $\\textbf{x}$\n",
    "\n",
    "Une prédiction est donnée par l'équatioin suivante:\n",
    "$$\n",
    "y = f(\\sum_i w_i \\cdot x_i + b)\n",
    "$$\n",
    "\n",
    "On utilise l'équation d'apprentissage suivante :\n",
    "$$\n",
    "\\theta^{n+1} = \\theta^n - \\eta\\nabla_\\theta E(y, t)\n",
    "$$\n",
    "\n",
    "Où $E$ désigne l'erreur commise par le modèle :\n",
    "$$\n",
    "E(y, t) = \\frac{1}{2}(y - t)^2\n",
    "$$\n",
    "\n",
    "L'équation d'apprentissage provient de la descente de gradient : pour minimiser l'erreur on suit l'opposé de la «direction» donnée par le gradient de l'erreur par rapport aux paramètres du modèle.\n",
    "Exemple : \n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_1} = \\frac{\\partial E}{\\partial y} \\frac{\\partial y}{\\partial w_1}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_1} = (y-t) \\times x_1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discriminator(predict_f, x, y):\n",
    "    \"\"\" \n",
    "    Plot a weight vector w = [w_0,w_1,w_2] as a colour map\n",
    "    \"\"\"\n",
    "    \n",
    "    xx,yy = np.mgrid[-5:5:.1,-5:5:0.1]\n",
    "\n",
    "    p = np.zeros(xx.shape)\n",
    "    for i in range(xx.shape[0]):\n",
    "        for j in range(xx.shape[1]):\n",
    "            p[i,j] = predict_f([xx[i,j], yy[i,j]])\n",
    "    plt.pcolor(xx,yy,p,cmap='seismic')\n",
    "    plt.xlim([-5, 5])\n",
    "    plt.ylim([-5, 5])    \n",
    "    plt.scatter(x[..., 0], x[..., 1], 20, colours)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "\"\"\"\n",
    "Ici on va tout coder de bout en bout pour un modèle simple.\n",
    "\"\"\"\n",
    "W = np.random.normal(0, 1, (2,))\n",
    "b = np.zeros(1)\n",
    "\n",
    "def reset_weights():\n",
    "    W = np.random.normal(0, 1, (2,))\n",
    "    b = np.zeros(1)\n",
    "\n",
    "def haversine(z):\n",
    "    return np.where(z >= 0, 1, 0)\n",
    "\n",
    "def predict_class_perceptron(X):\n",
    "    return haversine(W.dot(X) + b)\n",
    "\n",
    "def gradient(X, t):\n",
    "    \"\"\"\n",
    "    Doit calculer le gradient de E par rapport à W, puis le gradient de E par rapport à b et retourner les valeurs\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "learning_rate = 0.005\n",
    "plotme = True\n",
    "\n",
    "reset_weights()\n",
    "\n",
    "for e in range(10):\n",
    "    count = 0\n",
    "    correct, tot = 0, 0\n",
    "    for xt, yt in zip(x_train, y_train):\n",
    "        \n",
    "        if predict_class_perceptron(xt) != yt:\n",
    "            \"\"\"\n",
    "            Il faut mettre à jour les paramètres du modèle ici (W et b) !\n",
    "            \"\"\"\n",
    "        else:\n",
    "            correct += 1\n",
    "        tot += 1\n",
    "        \n",
    "        if plotme and count % 100==0:\n",
    "            plot_discriminator(predict_class_perceptron, x, y)\n",
    "        count += 1\n",
    "    print(f\"Epoch {e}, accuracy={correct/tot}\")\n",
    "    \n",
    "\"\"\"\n",
    "Evaluez le modèle final sur les données de test\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changeons maintenant de données d'entrainement pour des données un petit peu plus complexes et difficiles à séparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [[0.1, 1], [3, 4]]\n",
    "\n",
    "x2 = []\n",
    "y2 = []\n",
    "\n",
    "for (r_min, r_max), l in zip(r, labels):\n",
    "    rr = np.random.uniform(r_min, r_max, n//2)\n",
    "    theta = np.random.uniform(0, 2*np.pi, n//2)\n",
    "    x2.extend( np.concatenate((rr * np.cos(theta), \n",
    "                              rr * np.sin(theta))).reshape(2, n//2).T)\n",
    "    y2.extend([l] * (n//2))\n",
    "    \n",
    "x2 = np.array(x2)\n",
    "y2 = np.array(y2)\n",
    "\n",
    "plt.scatter(x2[:,0], x2[:,1], c=colours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "learning_rate = 0.01\n",
    "plotme = True\n",
    "\n",
    "reset_weights()\n",
    "\n",
    "for e in range(10):\n",
    "    count = 0\n",
    "    correct, tot = 0, 0\n",
    "    for xt, yt in zip(x_train, y_train):\n",
    "        \n",
    "        if predict_class_perceptron(xt) != yt:\n",
    "            \"\"\"\n",
    "            Il faut mettre à jour les paramètres du modèle ici (W et b) !\n",
    "            \"\"\"\n",
    "        else:\n",
    "            correct += 1\n",
    "        tot += 1\n",
    "        \n",
    "        if plotme and count % 100==0:\n",
    "            plot_discriminator(predict_class_perceptron, x2, y2)\n",
    "        count += 1\n",
    "    print(f\"Epoch {e}, accuracy={correct/tot}\")\n",
    "    \n",
    "\"\"\"\n",
    "Evaluez le modèle final sur les données de test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (MLP) or Neural Network (NN)\n",
    "![neuralnetwork](img/nn.jpeg)\n",
    "\n",
    "Accumulation de perceptron dans des «couches», puis accumulation de «couches».\n",
    "\n",
    "Les équations sont identiques à celles du perceptron. L'algorithme de propagation du gradient dans les couches est la «backpropagation»\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Slight modification on labels\n",
    "def one_hot(x):\n",
    "    l = len(x)\n",
    "    xx = np.zeros((l, 2))\n",
    "    xx[np.arange(l), x] = 1\n",
    "    return xx\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "\n",
    "# print(*((x, y) for x, y in zip(x_train, y_train)), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Liste de fonction d'activation:\n",
    "* tanh\n",
    "* sigmoid\n",
    "* relu\n",
    "* leaky_relu\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=tf.nn.tanh, input_shape=(2,)),\n",
    "    # Essayez d'introduire d'autres layers ici !\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=16)\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "plot_discriminator(lambda x: np.argmax(model.predict(np.array([x,]))), x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other algorithms\n",
    "\n",
    "* KNN\n",
    "\n",
    "* SVM\n",
    "\n",
    "* Tree based\n",
    "\n",
    "La librairie Sklearn contient beaucoup de modèles prêts à être utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\"\"\"\n",
    "Doc SKLEARN ici: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\"\"\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "print(np.mean(pred==y_test))\n",
    "plot_discriminator(lambda x: knn.predict([x])[0], x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\"\"\"\n",
    "Doc SKLEARN ici: https://scikit-learn.org/stable/modules/svm.html\n",
    "\"\"\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Linear Model\n",
    "svc = SVC(kernel='linear', )\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "pred = svc.predict(x_test)\n",
    "\n",
    "print(np.mean(pred==y_test))\n",
    "plot_discriminator(lambda x: svc.predict([x])[0], x2, y2)\n",
    "\n",
    "\"\"\"\n",
    "Changez le kernel (famille de fonction) du modèle\n",
    "\"\"\"\n",
    "\n",
    "# Polynomial Model\n",
    "\n",
    "\n",
    "# Exponential model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\"\"\"\n",
    "Doc SKLEARN ici: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\"\"\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "Implémentez un arbre de décision\n",
    "Essayez de jouer avec le paramètre `depth` (profondeur de l'arbre)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
